---
title: 聚类指标总结
date: 2025-04-09 16:19:36
tags:
    - study
categories:
    - Study
---

## 1. 一句话总结

- **优化指标**是“模型训练时要最小化/最大化的函数”；  
- **评估指标**是“训练完后用来衡量模型好坏的标准”。

<!-- more -->

## 2. 二者的详细对比

| 维度 | 优化指标（Objective/Loss Function） | 评估指标（Evaluation Metric） |
|------|--------------------------------------|---------------------------------|
|  作用 | 指导模型训练，决定梯度更新方向 | 衡量训练/测试后模型的好坏 |
|  使用阶段 | 模型训练阶段 | 模型评估阶段 |
|  目标 | 最小化（或最大化）它，让模型拟合数据 | 越高（或越低）代表模型性能越好 |
|  常见形式 | 损失函数，如 MSE、交叉熵、对比损失 | 准确率、F1、ARI、NMI、FMI 等 |
|  是否可微分 | 必须可导（用于反向传播） | 不一定可导（只用于观察效果） |
|  参与训练吗？ | ✅ 是训练核心 | ❌ 不参与训练，仅用于评估 |

## 3. 外部评估指标

### 3.1 Rand Index（RI）/Adjusted Rand Index（ARI）

#### 3.1.1 RI

##### 3.1.1.1 定义

- RI，基于**样本对的组合**来统计有多少对被正确分类（即一致地分在同一簇或不同簇中）

##### 3.1.1.2 核心思想

在所有可能的样本对中：

- **a**：同属一个类，聚类结果也分在同一个簇
- **b**：不同类，聚类也分在不同簇
- **c**：同属一个类，但聚类分到不同簇
- **d**：不同类，但聚类分到同一个簇

那么，RI 定义为：
$$
\text{RI} = \frac{a + b}{a + b + c + d}
$$
也就是所有一致判断的对数（a+b）占总对数的比例。

##### 3.1.1.3 范围

- RI ∈ [0, 1]，越接近1表示聚类越好。
- 缺点：对**随机聚类**也可能得到较高值，不稳健。
    > **随机聚类**指的是不基于任何数据结构或特征，而是随机地把数据样本划分到若干个簇中，就像“掷骰子决定每个样本属于哪个类”一样。

---

### 3.1.2 ARI

#### 3.1.2.1 定义

ARI 是对 RI 进行修正，**排除了随机结果带来的影响**，使得在随机聚类时 ARI 的期望值为 0。

公式（略复杂）为：
$$
\text{ARI} = \frac{\text{RI} - \mathbb{E}[\text{RI}]}{\max(\text{RI}) - \mathbb{E}[\text{RI}]}
$$
实际计算会用**组合数**来表达，具体计算公式是基于混淆矩阵的（即聚类 vs. 真实标签的交叉表）。

#### 3.1.2.2 特点

- ARI ∈ [-1, 1]：
  - 0 表示结果与随机分类一致
  - 1 表示完全一致
  - 小于 0 表示比随机还差
- 更稳健，广泛用于对聚类结果进行客观评价

---

### 3.1.3 举个简单例子

假设我们有 4 个样本，真实标签是 `[A, A, B, B]`，两个聚类结果：

- **聚类1**：`[1, 1, 2, 2]` （正确分类）
- **聚类2**：`[1, 2, 1, 2]` （错误分类）

- 聚类1的 ARI ≈ 1.0（完美匹配）
- 聚类2的 ARI ≈ -0.5（比随机还差）

---

#### 3.1.4 总结对比

| 指标 | 是否修正随机性 | 值域范围 | 推荐程度 |
|------|----------------|----------|-----------|
| RI   | 否             | [0, 1]   | 中        |
| ARI  | 是             | [-1, 1]  | 高       |

---

### 3.2 Mutual Information（MI）/Normalized Mutual Information（NMI）

#### 3.2.1 MI

##### 3.2.1.1 直觉理解

Mutual Information（互信息）来自信息论，用来衡量**两个变量共享了多少信息**。在聚类中，它衡量**聚类结果 $C$** 和 **真实标签 $L$** 之间的关联性。

> 如果知道聚类标签，可以推断出真实标签，那么说明互信息高，聚类结果好。

---

##### 3.2.1.2 数学定义

设真实标签集合为 $L = \{l_1, l_2, ..., l_K\}$，聚类结果为 $C = \{c_1, c_2, ..., c_J\}$，那么互信息定义为：

$$
MI(C, L) = \sum_{i=1}^{J} \sum_{j=1}^{K} P(c_i \cap l_j) \cdot \log \left( \frac{P(c_i \cap l_j)}{P(c_i) \cdot P(l_j)} \right)
$$

其中：

- $ P(c_i) $：样本属于第 $i$ 个聚类的概率
- $ P(l_j) $：样本属于第 $j$ 个真实类别的概率
- $ P(c_i \cap l_j) $：样本同时属于聚类 $c_i$ 和标签 $l_j$ 的概率

---

##### 3.2.1.3 但 MI 有个问题

- 它不是归一化的，取值范围依赖于聚类的复杂度。
- 不能直接比较不同聚类数时的聚类质量。

所以我们引入了NMI

---

#### 3.2.2 NMI

##### 3.2.2.1 直觉理解

NMI 是对 MI 的归一化版本，使其取值总在 [0, 1] 之间，更易比较。

##### 3.2.2.2 常见的定义公式

$$
\text{NMI}(C, L) = \frac{MI(C, L)}{ \sqrt{H(C) \cdot H(L)} }
$$

其中：

- $ H(C) $：聚类结果的熵
- $ H(L) $：真实标签的熵
- 熵的计算公式是：

$$
H(X) = -\sum_{x} P(x) \log P(x)
$$

也可以使用其他归一化形式，比如平均法：
$$
\text{NMI}(C, L) = \frac{2 \cdot MI(C, L)}{ H(C) + H(L) }
$$
这两种在 sklearn 中都支持。

---

##### 3.2.2.3 NMI 的特点

- 范围：$$ \text{NMI} \in [0, 1] $$
- **1 表示完全一致**，即聚类完美还原真实标签；
- **0 表示完全无关**，即聚类结果与标签完全不相关。

---

#### 3.2.3 🔍 小结对比

| 指标 | 概念 | 值域 | 是否归一化 | 说明 |
|------|------|------|--------------|------|
| MI   | 聚类和标签共享的信息量 | ≥0   | 否 | 越大表示越相关，但无法比较不同任务 |
| NMI  | 归一化的 MI            | [0,1] | ✅ | 越接近 1 越好，常用于聚类评价 |

---

### 3.3 Fowlkes–Mallows Index（FMI）

#### 3.3.1 FMI 是什么？

Fowlkes–Mallows Index（FMI）是一种基于**两两样本对（pairwise comparison）**的评估指标，它考虑了以下三类样本对的关系：

- **True Positive (TP)**：在聚类结果中被分到同一簇，并且在真实标签中也属于同一类。
- **False Positive (FP)**：在聚类中是同一簇，但真实标签不一样。
- **False Negative (FN)**：真实标签相同，但在聚类中被分到不同簇。

FMI 就是根据这些来评估聚类的好坏。

---

#### 3.3.2 FMI 的公式

$$
\text{FMI} = \frac{\text{TP}}{\sqrt{(\text{TP} + \text{FP}) \cdot (\text{TP} + \text{FN})}}
$$

##### 3.3.2.1 各部分解释

- 分子是 TP：聚类正确地把同类放在了一起
- 分母是 TP+FP 和 TP+FN 的几何平均，避免偏向于只考虑正例或负例

##### 3.3.2.2 FMI 的取值范围

- 取值范围为 [0, 1]
- **越接近 1** 表示聚类结果越接近真实标签
- **0 表示完全不匹配**，**1 表示完全匹配**

---

#### 3.3.3 FMI 的直观理解

设想我们要将学生分组，而我们事先知道他们的真实专业（真实标签），我们的聚类算法给出了分组结果。FMI 就是在问：

> “你分在一起的学生，真的都属于同一个专业吗？”  
> “那些应该属于一个专业的学生，你有没有漏掉没分在一起？”

---

#### 3.3.4 与其他指标比较

| 指标 | 特点 |
|------|------|
| FMI | 简洁明了，基于 pairwise 评估，直观易解释 |
| ARI（调整兰德指数） | 对随机分组结果进行惩罚，适合聚类数不同的情况 |
| NMI（归一化互信息） | 信息论角度衡量聚类与标签的相关性 |
| Purity | 更偏向分类准确率，但忽略了聚类结构整体性 |

 **FMI 特别适用于聚类类别数已知、数据量中等的情况。**

#### 3.3.5 总结

| 优点 | 缺点 |
|------|------|
| 简单易计算，解释直观，0-1之间好比较 | 不适用于无标签评估；聚类数差距大时不稳定 |

---

## 4. 内部评估指标

内部指标不依赖真实标签，仅依赖数据本身和聚类结果，常用于实际无标签任务。常见的有：

### 4.1 轮廓系数（Silhouette Coefficient）

- 结合了簇内相似度和簇间差异性。
- 取值范围 [-1, 1]，越接近1表示聚类效果越好。

公式：
$$
s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
$$

其中：

- $a(i)$：样本与本簇内其他样本的平均距离
- $b(i)$：样本与最近邻簇的平均距离

### 4.2 Davies-Bouldin Index（DBI）

- 衡量各簇之间的相对距离和散度。
- 数值越小表示簇分得越清晰。

### 4.3 Calinski-Harabasz Index（CH）

- 也叫方差比准则（Variance Ratio Criterion），衡量簇间方差与簇内方差之比。
- 值越大表示聚类越好。

---
